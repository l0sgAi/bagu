import{_ as e,c as t,o as s,aj as i}from"./chunks/framework.BZD6ashX.js";const d=JSON.parse('{"title":"🔍Elasticsearch全文搜索","description":"","frontmatter":{},"headers":[],"relativePath":"Elasticsearch.md","filePath":"Elasticsearch.md"}'),n={name:"Elasticsearch.md"};function a(l,r,o,g,p,h){return s(),t("div",null,[...r[0]||(r[0]=[i('<h1 id="🔍elasticsearch全文搜索" tabindex="-1">🔍Elasticsearch全文搜索 <a class="header-anchor" href="#🔍elasticsearch全文搜索" aria-label="Permalink to “🔍Elasticsearch全文搜索”">​</a></h1><h3 id="i-什么是倒排索引-inverted-index" tabindex="-1">I. 什么是倒排索引（Inverted Index）？ <a class="header-anchor" href="#i-什么是倒排索引-inverted-index" aria-label="Permalink to “I. 什么是倒排索引（Inverted Index）？”">​</a></h3><p><strong>核心概念：</strong> 将“文档➡️单词”的映射转换为“单词➡️ 文档列表”的映射。</p><ul><li><p><strong>Term Dictionary（词项字典）：</strong> 记录所有不重复的单词，通常使用 FST（Finite State Transducers）结构压缩存储在内存中，查询速度极快。</p></li><li><p><strong>Posting List（倒排列表）：</strong> 记录单词对应的文档 ID 集合（以及词频、位置等信息）。通过 Frame of Reference (FOR) 和 Roaring Bitmap 进行压缩。</p></li><li><p><strong>作用：</strong> 实现全文检索的关键，能快速找到包含特定关键词的所有文档。</p></li></ul><h3 id="ii-es-的写入流程是怎样的" tabindex="-1">II. ES 的写入流程是怎样的？ <a class="header-anchor" href="#ii-es-的写入流程是怎样的" aria-label="Permalink to “II. ES 的写入流程是怎样的？”">​</a></h3><p><strong>宏观流程：</strong> 客户端 ➡️ 协调节点 -&gt; 主分片（Primary Shard）➡️副本分片（Replica Shard）。<br><strong>微观流程（数据持久化）：</strong></p><ol><li><p><strong>Buffer &amp; Translog：</strong> 数据先写入内存 Buffer，同时追加到 Translog（事务日志，防止断电丢失）。</p></li><li><p><strong>Refresh（默认1秒）：</strong> Buffer 中的数据生成 Segment 文件写入 <strong>Filesystem Cache</strong>（系统缓存），此时数据<strong>可被搜索</strong>，但未落盘。Buffer 清空。</p></li><li><p><strong>Flush（默认30分钟或Translog满）：</strong> 触发 Commit 操作，强制将 Filesystem Cache 中的 Segment 刷入磁盘，清空 Translog。</p></li></ol><h3 id="iii-es-的读取-搜索流程-query-then-fetch" tabindex="-1">III. ES 的读取/搜索流程（Query Then Fetch）？ <a class="header-anchor" href="#iii-es-的读取-搜索流程-query-then-fetch" aria-label="Permalink to “III. ES 的读取/搜索流程（Query Then Fetch）？”">​</a></h3><p>搜索分为两个阶段：</p><ol><li><p><strong>Query 阶段：</strong></p><ul><li><p>协调节点将请求广播到所有相关的分片（主或副）。</p></li><li><p>每个分片在本地查询，返回<strong>文档 ID</strong> 和 <strong>打分（Score）</strong> 给协调节点。</p></li><li><p>协调节点进行全局排序和合并。</p></li></ul></li><li><p><strong>Fetch 阶段：</strong></p><ul><li><p>协调节点根据确定的文档 ID，向对应的分片发送请求抓取实际的文档内容（_source）。</p></li><li><p>分片返回数据，协调节点拼装最终结果返回给客户端。</p></li></ul></li></ol><h3 id="iv-什么是深度分页-deep-pagination-如何解决" tabindex="-1">IV. 什么是深度分页（Deep Pagination）？如何解决？ <a class="header-anchor" href="#iv-什么是深度分页-deep-pagination-如何解决" aria-label="Permalink to “IV. 什么是深度分页（Deep Pagination）？如何解决？”">​</a></h3><p><strong>问题：</strong> 使用 <code>from</code> + <code>size</code> 分页时，若请求第 10000 页（每页10条），每个分片都需要查出前 100010 条数据，协调节点要汇总 shards * 100010 条数据排序，最后只取 10 条。这会导致大量的 CPU 和内存消耗（OOM）。<br><strong>解决方案：</strong></p><ol><li><p><strong>Scroll（游标）：</strong> 创建快照，适合全量数据导出，不适合实时查询（因为无法获取新写入的数据）。</p></li><li><p><strong>Search After：</strong> 基于上一页最后一条数据的排序值（Sort values）来查询下一页。性能好，适合无限下拉加载，但不支持随机跳转页码。</p></li></ol><h3 id="v-es-如何解决-脑裂-问题" tabindex="-1">V. ES 如何解决“脑裂”问题？ <a class="header-anchor" href="#v-es-如何解决-脑裂-问题" aria-label="Permalink to “V. ES 如何解决“脑裂”问题？”">​</a></h3><p><strong>现象：</strong> 集群因网络波动分裂，出现两个主节点（Master），导致数据不一致。<br><strong>解决方案：</strong></p><ul><li><p><strong>核心原则：</strong> <strong>Quorum（法定票数）</strong>。</p></li><li><p><strong>配置：</strong> 设置 discovery.zen.minimum_master_nodes = N/2 + 1（其中 N 是有资格成为 Master 的节点数）。即只有获得过半节点支持才能当选 Master。</p><ul><li>注：ES 7.0 以后引入了新的集群协调子系统，移除该配置，系统会自动处理，但在设计集群拓扑时仍需注意节点规划。</li></ul></li></ul><h3 id="vi-es-性能调优有哪些常见手段" tabindex="-1">VI. ES 性能调优有哪些常见手段？ <a class="header-anchor" href="#vi-es-性能调优有哪些常见手段" aria-label="Permalink to “VI. ES 性能调优有哪些常见手段？”">​</a></h3><p><strong>写入优化：</strong></p><ul><li><p><strong>使用 Bulk 请求：</strong> 批量写入。</p></li><li><p><strong>加大 Refresh Interval：</strong> 默认1秒，导入大量数据时可改为 -1 或 30s，减少 Segment 合并压力。</p></li><li><p><strong>使用自动生成的 ID：</strong> 避免检查 ID 冲突。</p></li><li><p><strong>初次导入禁用 Replicas：</strong> 导入完成后再开启副本。</p></li></ul><p><strong>查询优化：</strong></p><ul><li><p><strong>使用 Filter 代替 Query：</strong> Filter 不计算分数且支持缓存。</p></li><li><p><strong>路由（Routing）：</strong> 写入和查询时指定路由键，避免扫描所有分片。</p></li><li><p><strong>硬件层面：</strong> 使用 SSD，且给 Filesystem Cache 预留一半内存（ES 堆内存建议不要超过 32GB）。</p></li><li><p><strong>避免大宽表：</strong> 减少 text 字段，不需要分词的字段使用 keyword。</p></li></ul><h3 id="vii-es-更新和删除文档的原理" tabindex="-1">VII. ES 更新和删除文档的原理？ <a class="header-anchor" href="#vii-es-更新和删除文档的原理" aria-label="Permalink to “VII. ES 更新和删除文档的原理？”">​</a></h3><p>ES 的 Segment 文件是<strong>不可修改</strong>的。</p><ul><li><p><strong>删除：</strong> 不会物理删除，只是在 .del 文件中将该文档标记为“deleted”。搜索时会过滤掉这些文档。</p></li><li><p><strong>更新：</strong> 本质是 <strong>Delete + Insert</strong>。先将旧文档标记删除，再写入新文档。</p></li><li><p><strong>物理清理：</strong> 在 Segment Merge（段合并）阶段，才会真正物理移除被标记删除的数据。</p></li></ul><h3 id="viii-es的刷新延时配置是什么" tabindex="-1">VIII. ES的刷新延时配置是什么？ <a class="header-anchor" href="#viii-es的刷新延时配置是什么" aria-label="Permalink to “VIII. ES的刷新延时配置是什么？”">​</a></h3><p>即Elasticsearch中的 <strong>refresh_interval配置</strong>。</p><h5 id="_1-这个配置是什么" tabindex="-1">1. 这个配置是什么？ <a class="header-anchor" href="#_1-这个配置是什么" aria-label="Permalink to “1. 这个配置是什么？”">​</a></h5><ul><li><p><strong>参数名：</strong> index.refresh_interval</p></li><li><p><strong>默认值：</strong> 1s（1秒）</p></li><li><p><strong>含义：</strong> 数据写入 ES 后，多久可以被<strong>搜索</strong>到。</p></li><li><p><strong>核心概念：</strong> 这就是为什么 ES 被称为 <strong>“近实时”（Near Real-Time, NRT）</strong> 搜索引擎的原因。数据写进去了，但默认要过 1 秒才能查出来。</p></li></ul><h5 id="_2-底层原理-简述" tabindex="-1">2. 底层原理（简述） <a class="header-anchor" href="#_2-底层原理-简述" aria-label="Permalink to “2. 底层原理（简述）”">​</a></h5><ol><li><p><strong>写入 Buffer：</strong> 数据先写入内存缓冲区（Memory Buffer）。</p></li><li><p><strong>Refresh（刷新）：</strong> 每隔 refresh_interval（默认1秒），ES 会把缓冲区的数据“刷”到文件系统缓存（FileSystem Cache）中，生成一个新的 <strong>Segment</strong>。</p></li><li><p><strong>可见性：</strong> 一旦生成 Segment，数据就可以被搜索到了（虽然此时还没彻底落盘到硬盘，但在缓存里已可见）。</p></li></ol><h5 id="_3-考察点" tabindex="-1">3. 考察点 <a class="header-anchor" href="#_3-考察点" aria-label="Permalink to “3. 考察点”">​</a></h5><p><strong>海量数据写入性能优化</strong></p><ul><li><p><strong>问题所在：</strong> 默认 1秒一次 Refresh，如果正在进行大量数据写入（比如批量导入 1 亿条日志），频繁生成小的 Segment 会消耗大量 CPU 和 I/O 资源，严重拖慢写入速度。</p></li><li><p><strong>优化方案：</strong> 在批量写入期间，将 refresh_interval 设置为 -1（关闭刷新）或者设置得很大（比如 30s）。</p><ul><li><p><strong>好处：</strong> 减少 Segment 的生成频率，大幅提升写入吞吐量。</p></li><li><p><strong>代价：</strong> 在这期间写入的数据无法被立即搜索到（等批量写完再改回 1s）。</p></li></ul></li></ul>',33)])])}const m=e(n,[["render",a]]);export{d as __pageData,m as default};
