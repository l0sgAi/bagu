import{_ as l,c as s,o as a,aj as r}from"./chunks/framework.BZD6ashX.js";const c=JSON.parse('{"title":"❤️‍🔥高性能Redis","description":"","frontmatter":{},"headers":[],"relativePath":"高性能Redis.md","filePath":"高性能Redis.md"}'),e={name:"高性能Redis.md"};function t(o,i,n,p,g,d){return a(),s("div",null,[...i[0]||(i[0]=[r('<h1 id="❤️‍🔥高性能redis" tabindex="-1">❤️‍🔥高性能Redis <a class="header-anchor" href="#❤️‍🔥高性能redis" aria-label="Permalink to “❤️‍🔥高性能Redis”">​</a></h1><h3 id="i-核心架构与原理" tabindex="-1">I. 核心架构与原理 <a class="header-anchor" href="#i-核心架构与原理" aria-label="Permalink to “I. 核心架构与原理”">​</a></h3><h4 id="_1-redis-为什么这么快" tabindex="-1">1. Redis 为什么这么快？ <a class="header-anchor" href="#_1-redis-为什么这么快" aria-label="Permalink to “1. Redis 为什么这么快？”">​</a></h4><p><strong>简答：</strong><br> 主要有三个原因：</p><ol><li><p><strong>纯内存操作：</strong> 数据都在内存中，读写速度非常快（纳秒级）。</p></li><li><p><strong>单线程模型（核心）：</strong> 避免了多线程的上下文切换（Context Switch）和锁竞争（Locking）的开销。</p></li><li><p><strong>I/O 多路复用：</strong> 采用了 Reactor 模式（如 Linux 下的 epoll），能在一个线程中非阻塞地处理大量并发网络连接。</p></li></ol><h4 id="_2-redis-是完全单线程的吗-6-0-引入多线程是为了什么" tabindex="-1">2. Redis 是完全单线程的吗？6.0 引入多线程是为了什么？ <a class="header-anchor" href="#_2-redis-是完全单线程的吗-6-0-引入多线程是为了什么" aria-label="Permalink to “2. Redis 是完全单线程的吗？6.0 引入多线程是为了什么？”">​</a></h4><p><strong>简答：</strong></p><ul><li><p><strong>不是完全单线程。</strong> 在 Redis 4.0 之后就引入了后台线程处理耗时任务（如 UNLINK 删除大 Key）。</p></li><li><p><strong>Redis 6.0 引入多线程：</strong> 主要是为了解决<strong>网络 I/O 的瓶颈</strong>。</p><ul><li><p>核心命令执行（计算）依然是<strong>单线程</strong>的（保证了线程安全，无需加锁）。</p></li><li><p><strong>多线程只用于：</strong> 网络数据的读写（Socket Read/Write）和协议解析。</p></li></ul></li></ul><h4 id="_3-什么是-i-o-多路复用" tabindex="-1">3. 什么是 I/O 多路复用？ <a class="header-anchor" href="#_3-什么是-i-o-多路复用" aria-label="Permalink to “3. 什么是 I/O 多路复用？”">​</a></h4><p><strong>简答：</strong><br> Redis 利用 epoll 机制，让一个线程同时监听多个 Socket（客户端连接）。当某个 Socket 有数据到达（可读/可写）时，内核会通知 Redis，Redis 再去处理。这避免了为了等待 IO 而阻塞线程，极大地提升了并发处理能力。</p><hr><h3 id="ii-数据结构与底层实现-怎么省" tabindex="-1">II. 数据结构与底层实现（怎么省？） <a class="header-anchor" href="#ii-数据结构与底层实现-怎么省" aria-label="Permalink to “II.  数据结构与底层实现（怎么省？）”">​</a></h3><h4 id="_4-redis-的字符串-string-底层为什么用-sds-而不是-c-字符串" tabindex="-1">4. Redis 的字符串（String）底层为什么用 SDS 而不是 C 字符串？ <a class="header-anchor" href="#_4-redis-的字符串-string-底层为什么用-sds-而不是-c-字符串" aria-label="Permalink to “4. Redis 的字符串（String）底层为什么用 SDS 而不是 C 字符串？”">​</a></h4><p><strong>简答：</strong><br> SDS（Simple Dynamic String）相比 C 语言原生字符串有以下优势：</p><ol><li><p><strong>O(1) 获取长度：</strong> SDS 头部记录了 len，无需遍历。</p></li><li><p><strong>杜绝缓冲区溢出：</strong> 修改字符串时会自动扩容。</p></li><li><p><strong>减少内存重分配：</strong> 采用“空间预分配”和“惰性空间释放”策略。</p></li><li><p><strong>二进制安全：</strong> 可以存储包含空字符 \\0 的数据（如图片、视频流）。</p></li></ol><h4 id="_5-跳表-skiplist-是什么-为什么-zset-用它而不用红黑树" tabindex="-1">5. 跳表（SkipList）是什么？为什么 ZSet 用它而不用红黑树？ <a class="header-anchor" href="#_5-跳表-skiplist-是什么-为什么-zset-用它而不用红黑树" aria-label="Permalink to “5. 跳表（SkipList）是什么？为什么 ZSet 用它而不用红黑树？”">​</a></h4><p><strong>简答：</strong><br> 跳表是一种基于链表的随机化数据结构，通过多层索引实现快速查找。</p><ul><li><p><strong>复杂度：</strong> 查找、插入、删除平均均为</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span>O(logN)</span></span></code></pre></div><p>。</p></li><li><p><strong>对比红黑树：</strong></p><ol><li><p><strong>实现简单：</strong> 代码容易实现和调试。</p></li><li><p><strong>区间查找更优：</strong> ZSet 经常需要范围查找（如排行榜），跳表只需找到起点然后遍历链表即可，红黑树则较复杂。</p></li><li><p><strong>并发调整代价小：</strong> 虽然 Redis 是单线程，但在理论上跳表插入节点只需修改局部指针。</p></li></ol></li></ul><h4 id="_6-压缩列表-ziplist-listpack-是为了解决什么问题" tabindex="-1">6. 压缩列表（Ziplist/Listpack）是为了解决什么问题？ <a class="header-anchor" href="#_6-压缩列表-ziplist-listpack-是为了解决什么问题" aria-label="Permalink to “6. 压缩列表（Ziplist/Listpack）是为了解决什么问题？”">​</a></h4><p><strong>简答：</strong><br> 为了<strong>节省内存</strong>。当 Hash、List、ZSet 元素较少且较小时，Redis 会使用一块连续的内存空间（压缩列表）来紧凑存储数据，避免了指针带来的内存碎片和额外开销。<br> (注：Redis 7.0 后主要使用 Listpack 替代 Ziplist)</p><hr><h3 id="iii-内存管理与持久化-怎么稳" tabindex="-1">III. 内存管理与持久化（怎么稳？） <a class="header-anchor" href="#iii-内存管理与持久化-怎么稳" aria-label="Permalink to “III.  内存管理与持久化（怎么稳？）”">​</a></h3><h4 id="_7-redis-的过期策略是什么" tabindex="-1">7. Redis 的过期策略是什么？ <a class="header-anchor" href="#_7-redis-的过期策略是什么" aria-label="Permalink to “7. Redis 的过期策略是什么？”">​</a></h4><p><strong>简答：</strong><br> 采用 <strong>惰性删除 + 定期删除</strong> 相结合的策略。</p><ul><li><p><strong>惰性删除：</strong> 访问 Key 时，检查是否过期，过期则删除。优点是省 CPU，缺点是可能残留垃圾数据。</p></li><li><p><strong>定期删除：</strong> 每隔一段时间随机抽取一部分 Key 进行检查和删除。</p></li></ul><h4 id="_8-内存淘汰策略-eviction-policy-有哪些-lru-和-lfu-的区别" tabindex="-1">8. 内存淘汰策略（Eviction Policy）有哪些？LRU 和 LFU 的区别？ <a class="header-anchor" href="#_8-内存淘汰策略-eviction-policy-有哪些-lru-和-lfu-的区别" aria-label="Permalink to “8. 内存淘汰策略（Eviction Policy）有哪些？LRU 和 LFU 的区别？”">​</a></h4><p><strong>简答：</strong><br> 当内存满了（达到 maxmemory）时触发。常见的有：</p><ul><li><p>noeviction：报错（默认）。</p></li><li><p>allkeys-lru / volatile-lru：移除最近最少使用的 Key。</p></li><li><p><strong>LRU (Least Recently Used)：</strong> 基于<strong>时间</strong>，淘汰很久没用的。</p></li><li><p><strong>LFU (Least Frequently Used)：</strong> 基于<strong>频率</strong>，淘汰用得最少的（更能反映热点）。</p></li></ul><h4 id="_9-aof-和-rdb-持久化对性能的影响" tabindex="-1">9. AOF 和 RDB 持久化对性能的影响？ <a class="header-anchor" href="#_9-aof-和-rdb-持久化对性能的影响" aria-label="Permalink to “9. AOF 和 RDB 持久化对性能的影响？”">​</a></h4><p><strong>简答：</strong></p><ul><li><p><strong>RDB（快照）：</strong> 生成快照时会 fork 子进程，<strong>fork 操作会阻塞主线程</strong>。如果内存数据非常大（如几十 GB），fork 可能会导致毫秒甚至秒级停顿。</p></li><li><p><strong>AOF（日志）：</strong></p><ul><li><p>appendfsync always：每次写都刷盘，性能极差。</p></li><li><p>appendfsync everysec：每秒刷盘，折中方案（推荐）。</p></li><li><p>AOF rewrite 同样需要 fork 子进程，也有阻塞风险。</p></li></ul></li></ul><hr><h3 id="iv-经典性能问题与场景-怎么避坑" tabindex="-1">IV. 经典性能问题与场景（怎么避坑？） <a class="header-anchor" href="#iv-经典性能问题与场景-怎么避坑" aria-label="Permalink to “IV.  经典性能问题与场景（怎么避坑？）”">​</a></h3><h4 id="_10-什么是缓存穿透、击穿、雪崩-怎么解决" tabindex="-1">10. 什么是缓存穿透、击穿、雪崩？怎么解决？ <a class="header-anchor" href="#_10-什么是缓存穿透、击穿、雪崩-怎么解决" aria-label="Permalink to “10. 什么是缓存穿透、击穿、雪崩？怎么解决？”">​</a></h4><p><strong>简答：</strong></p><ul><li><p><strong>缓存穿透（查不到）：</strong> 查询不存在的数据，请求直打数据库。</p><ul><li>解法： 布隆过滤器（Bloom Filter）、缓存空对象。</li></ul></li><li><p><strong>缓存击穿（热点失效）：</strong> 单个热点 Key 过期，并发请求瞬间击垮数据库。</p><ul><li>解法： 互斥锁（Mutex）、逻辑过期（不设置真实 TTL，后台异步更新）。</li></ul></li><li><p><strong>缓存雪崩（集体失效）：</strong> 大量 Key 同时过期或 Redis 宕机。</p><ul><li>解法： 设置随机过期时间、Redis 高可用（Cluster/Sentinel）、限流降级。</li></ul></li></ul><h4 id="_11-如何处理-big-key-大-key" tabindex="-1">11. 如何处理 Big Key（大 Key）？ <a class="header-anchor" href="#_11-如何处理-big-key-大-key" aria-label="Permalink to “11. 如何处理 Big Key（大 Key）？”">​</a></h4><p><strong>简答：</strong><br> Big Key 会导致读写阻塞、网络阻塞、删除阻塞，因为Redis本质单线程。</p><ul><li><p><strong>发现：</strong> 使用 --bigkeys 参数或 RDB 分析工具。</p></li><li><p><strong>原因：</strong></p><ol><li><p>业务设计本身不合理，需要考虑重新设计缓存策略。</p></li><li><p>没有定期的删除机制、合理的过期机制或者最大容量限制。</p></li></ol></li><li><p><strong>解决：</strong></p><ol><li><p><strong>拆分：</strong> 把大 Hash 拆成多个小 Hash。</p></li><li><p><strong>异步删除：</strong> 使用 UNLINK 命令代替 DEL，在后台线程释放内存，避免阻塞主线程。</p></li></ol></li></ul><h4 id="_12-redis-变慢了-如何排查" tabindex="-1">12. Redis 变慢了，如何排查？ <a class="header-anchor" href="#_12-redis-变慢了-如何排查" aria-label="Permalink to “12. Redis 变慢了，如何排查？”">​</a></h4><p><strong>简答：</strong><br> 按以下顺序排查：</p><ol><li><p><strong>命令复杂度：</strong> 是否使用了</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span>O(N)</span></span></code></pre></div><p>的命令（如 KEYS *, HGETALL）。</p></li><li><p><strong>Big Key：</strong> 是否有大 Key 的读写或删除。</p></li><li><p><strong>持久化：</strong> 检查是否频繁 fork 导致阻塞，或 AOF 刷盘阻塞。</p></li><li><p><strong>内存使用：</strong> 是否触发了 Swap（交换分区），这会极度降低性能。</p></li><li><p><strong>网络带宽：</strong> 是否流量打满。</p></li></ol><hr><h3 id="v-分布式锁相关" tabindex="-1">V. 分布式锁相关 <a class="header-anchor" href="#v-分布式锁相关" aria-label="Permalink to “V. 分布式锁相关”">​</a></h3><p>Redisson 是一个在 Redis 基础上实现的 Java 驻内存数据网格（In-Memory Data Grid）。它实现分布式锁的核心思路是：<strong>Lua 脚本 + Hash 数据结构 + 看门狗机制（Watchdog）。</strong></p><h4 id="_1-解决-锁过期但业务没跑完-——-看门狗机制-watchdog" tabindex="-1">1. 解决“锁过期但业务没跑完” —— 看门狗机制（Watchdog） <a class="header-anchor" href="#_1-解决-锁过期但业务没跑完-——-看门狗机制-watchdog" aria-label="Permalink to “1. 解决“锁过期但业务没跑完” —— 看门狗机制（Watchdog）”">​</a></h4><p>这是 Redisson 最亮眼的功能。</p><ul><li><p><strong>原理</strong>：</p><ul><li><p>当你加锁时，如果没有指定过期时间，Redisson 会默认设置一个 30 秒的过期时间（LockWatchdogTimeout）。</p></li><li><p>Redisson 会启动一个后台线程（定时任务），每隔 LockWatchdogTimeout / 3 （默认 10 秒）就会去检查一下：“持有锁的线程还在吗？”</p></li><li><p><strong>如果还在，就将锁的过期时间重新重置为 30 秒</strong>（这个过程叫“续期”）。</p></li><li><p>只要业务不跑完，锁的时间就会一直续期，永远不会过期。</p></li><li><p>如果客户端宕机了（Watchdog 也就挂了），无法续期，Redis 里的锁会在 30 秒后自动过期，防止死锁。</p></li></ul></li></ul><h4 id="_2-解决-误删别人的锁-——-uuid-校验-lua-脚本" tabindex="-1">2. 解决“误删别人的锁” —— UUID 校验 + Lua 脚本 <a class="header-anchor" href="#_2-解决-误删别人的锁-——-uuid-校验-lua-脚本" aria-label="Permalink to “2. 解决“误删别人的锁” —— UUID 校验 + Lua 脚本”">​</a></h4><ul><li><p>Redisson 在加锁时，Value 存的不是乱七八糟的值，而是 <strong>UUID + 线程ID</strong>。</p></li><li><p>在释放锁时，Redisson 使用 <strong>Lua 脚本</strong>（保证原子性）去判断：</p><ul><li><p>当前锁是否存在？</p></li><li><p>当前锁 Value 里的 ID 是不是我自己的 ID？</p></li><li><p>如果是，才执行 DEL；如果不是，说明锁已经过期被别人抢了，我就不删了。</p></li></ul></li></ul><h4 id="_3-解决-不可重入-——-使用-hash-结构" tabindex="-1">3. 解决“不可重入” —— 使用 Hash 结构 <a class="header-anchor" href="#_3-解决-不可重入-——-使用-hash-结构" aria-label="Permalink to “3. 解决“不可重入” —— 使用 Hash 结构”">​</a></h4><ul><li><p>Redisson 底层不使用 String (SETNX)，而是使用 <strong>Hash</strong> 结构。</p></li><li><p><strong>Key</strong>: 锁的名称。</p></li><li><p><strong>Field</strong>: UUID + 线程 ID。</p></li><li><p><strong>Value</strong>: <strong>计数器（Count）</strong>。</p></li><li><p><strong>原理</strong>：</p><ul><li><p>第一次加锁：在 Hash 中写入字段，将 Value 设为 1。</p></li><li><p>再次加锁（重入）：发现 Field 是当前线程，将 Value + 1（变为 2）。</p></li><li><p>释放锁：将 Value - 1。当 Value 变为 0 时，才真正从 Redis 中删除 Key。</p></li><li><p>这完全模拟了 Java 中 ReentrantLock 的机制。</p></li></ul></li></ul><h4 id="_4-解决-原子性-——-全程-lua-脚本" tabindex="-1">4. 解决“原子性” —— 全程 Lua 脚本 <a class="header-anchor" href="#_4-解决-原子性-——-全程-lua-脚本" aria-label="Permalink to “4. 解决“原子性” —— 全程 Lua 脚本”">​</a></h4><ul><li><p>Redisson 的加锁、释放锁、续期操作，全部都是通过 <strong>Lua 脚本</strong> 发送给 Redis 执行的。</p></li><li><p>Redis 执行 Lua 脚本是原子的，中间不会被插入其他命令，保证了逻辑的严密性。</p></li></ul><hr><h3 id="✨其它" tabindex="-1">✨其它 <a class="header-anchor" href="#✨其它" aria-label="Permalink to “✨其它”">​</a></h3><ol><li><p><strong>Pipeline（管道）：</strong> 批量执行命令，减少 RTT（网络往返时间）。</p></li><li><p><strong>Lua 脚本：</strong> 保证多条命令执行的原子性，减少网络开销。</p></li><li><p><strong>Copy On Write (COW)：</strong> 解释 RDB fork 子进程时，操作系统利用 COW 机制共享内存，只有写操作时才复制页，从而提高效率。</p></li></ol>',57)])])}const u=l(e,[["render",t]]);export{c as __pageData,u as default};
