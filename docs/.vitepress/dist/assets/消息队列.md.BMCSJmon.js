import{_ as t,c as o,o as e,aj as l}from"./chunks/framework.BZD6ashX.js";const c=JSON.parse('{"title":"🚟消息队列","description":"","frontmatter":{},"headers":[],"relativePath":"消息队列.md","filePath":"消息队列.md"}'),i={name:"消息队列.md"};function n(a,r,s,p,g,d){return e(),o("div",null,[...r[0]||(r[0]=[l('<h1 id="🚟消息队列" tabindex="-1">🚟消息队列 <a class="header-anchor" href="#🚟消息队列" aria-label="Permalink to “🚟消息队列”">​</a></h1><h3 id="i-如何解决消息丢失问题" tabindex="-1">I. 如何解决消息丢失问题？ <a class="header-anchor" href="#i-如何解决消息丢失问题" aria-label="Permalink to “I. 如何解决消息丢失问题？”">​</a></h3><p>消息丢失可能发生在三个阶段，我们需要分段治理：</p><h4 id="_1-生产者丢失消息-producer-➡️-broker" tabindex="-1">1. 生产者丢失消息（Producer ➡️ Broker） <a class="header-anchor" href="#_1-生产者丢失消息-producer-➡️-broker" aria-label="Permalink to “1. 生产者丢失消息（Producer ➡️ Broker）”">​</a></h4><p><strong>原因</strong>：网络波动、Broker 宕机，导致消息根本没发到 Broker，但生产者以为发了。<br><strong>解决方案</strong>：</p><ul><li><p><strong>开启发布确认机制 (Publisher Confirm)</strong>：</p><ul><li><p>生产者将 Channel 设置为 confirm 模式。</p></li><li><p>每发送一条消息，Broker 收到并写入磁盘后，会给生产者回传一个 ACK。</p></li><li><p>如果生产者没收到 ACK（或收到 NACK），就重试发送。</p></li></ul></li><li><p><strong>备选：事务机制 (Transaction)</strong>：虽然也能保证安全，但性能极差，通常不推荐。</p></li></ul><h4 id="_2-broker-丢失消息-broker-自身" tabindex="-1">2. Broker 丢失消息（Broker 自身） <a class="header-anchor" href="#_2-broker-丢失消息-broker-自身" aria-label="Permalink to “2. Broker 丢失消息（Broker 自身）”">​</a></h4><p><strong>原因</strong>：Broker 接收到了消息，但还没来得及写入磁盘就宕机了（内存数据丢失）。<br><strong>解决方案</strong>：<strong>持久化 (Persistence)</strong>。<br> 需要同时做3️⃣件事，缺一不可：</p><ol><li><p><strong>Exchange 持久化</strong>：声明交换机时 durable=true。</p></li><li><p><strong>Queue 持久化</strong>：声明队列时 durable=true。</p></li><li><p><strong>Message 持久化</strong>：发送消息时设置投递模式 deliveryMode=2。</p></li></ol><h4 id="_3-消费者丢失消息-broker-➡️-consumer" tabindex="-1">3. 消费者丢失消息（Broker ➡️ Consumer） <a class="header-anchor" href="#_3-消费者丢失消息-broker-➡️-consumer" aria-label="Permalink to “3. 消费者丢失消息（Broker ➡️ Consumer）”">​</a></h4><p><strong>原因</strong>：消费者开启了“自动确认”（Auto Ack）。消息刚被消费者接收（还在内存中没处理），消费者进程挂了，Broker 以为已经消费成功，就把消息删了。<br><strong>解决方案</strong>：</p><ul><li><p><strong>关闭自动确认，开启手动确认 (Manual Ack)</strong>。</p></li><li><p>消费者在业务逻辑<strong>完全处理成功后</strong>，才调用 channel.basicAck() 告诉 Broker 可以删除消息。</p></li><li><p>如果处理失败，可以调用 basicNack 或 basicReject 让消息重新入队。</p></li></ul><hr><h3 id="ii-如何解决消息重复问题" tabindex="-1">II. 如何解决消息重复问题？ <a class="header-anchor" href="#ii-如何解决消息重复问题" aria-label="Permalink to “II.  如何解决消息重复问题？”">​</a></h3><p><strong>原因</strong>：</p><ul><li><p><strong>网络抖动</strong>：生产者发了消息，Broker 收到了，但回传 ACK 时网络断了。生产者以为失败了，就重发了一次。</p></li><li><p><strong>消费者故障</strong>：消费者处理完了业务，还没来得及发 ACK 就挂了。Broker 以为没处理，就把消息发给另一个消费者。</p></li></ul><p><strong>解决方案</strong>：<br> 消息重复在分布式系统中是<strong>无法完全避免</strong>的（为了保证不丢失，通常采用“至少一次投递”策略）。<br> 所以，解决方案的核心不在于“不让它重复发”，而在于<strong>消费者端的幂等性 (Idempotency) 处理</strong>。</p><p><strong>具体手段</strong>：</p><ol><li><p><strong>数据库唯一约束 (最强硬手段)</strong>：</p><ul><li><p>给每条消息生成一个全局唯一的 ID（MessageID 或业务 ID，如订单号）。</p></li><li><p>消费时，尝试向数据库（或去重表）插入这个 ID。</p></li><li><p>如果插入成功，则执行业务；如果报错（主键冲突），说明已经消费过，直接丢弃或 ACK。</p></li></ul></li><li><p><strong>Redis 原子操作 (性能较好)</strong>：</p><ul><li><p>利用 SETNX (set if not exists) 命令。</p></li><li><p>Key 为消息 ID，Value 为状态。</p></li><li><p>处理前先 SETNX，返回 true 则处理，返回 false 则说明正在处理或已处理。</p></li></ul></li><li><p><strong>乐观锁/版本号</strong>：</p><ul><li>如果是更新操作，带上版本号条件：UPDATE table SET count = count + 1, version = version + 1 WHERE id = 1 AND version = 1。</li></ul></li></ol><hr><h3 id="iii-如何解决消息积压问题" tabindex="-1">III. 如何解决消息积压问题？ <a class="header-anchor" href="#iii-如何解决消息积压问题" aria-label="Permalink to “III. 如何解决消息积压问题？”">​</a></h3><p><strong>表现</strong>：</p><ul><li><p>消费者挂了。</p></li><li><p>消费者处理速度太慢（代码逻辑耗时、数据库瓶颈）。</p></li><li><p>生产者发送流量突然暴涨（秒杀活动）。</p></li></ul><p><strong>根本原因：</strong></p><ul><li><p>业务设计与实际流量不匹配。</p></li><li><p>偶然的、未在设计预期内的短时高流量。</p></li></ul><p><strong>解决方案</strong>：</p><h4 id="_1-紧急处理-线上已经积压了怎么办" tabindex="-1">1. 紧急处理（线上已经积压了怎么办？） <a class="header-anchor" href="#_1-紧急处理-线上已经积压了怎么办" aria-label="Permalink to “1. 紧急处理（线上已经积压了怎么办？）”">​</a></h4><p>如果积压了几百万条消息，直接加消费者可能来不及，或者数据库扛不住。<br><strong>临时扩容方案</strong>：</p><ol><li><p><strong>修复消费者</strong>：先确保消费者逻辑没 Bug。</p></li><li><p><strong>限流、降级</strong>：停止现有消费者，或者将它们降级。</p></li><li><p><strong>部署大量消费者</strong>：临时部署 10-20 倍的消费者节点，专门消费那些临时队列。</p></li><li><p><strong>恢复</strong>：积压消费完后，恢复原有架构。</p></li></ol><h4 id="_2-预防措施-长期治理" tabindex="-1">2. 预防措施（长期治理） <a class="header-anchor" href="#_2-预防措施-长期治理" aria-label="Permalink to “2. 预防措施（长期治理）”">​</a></h4><ul><li><p><strong>重新评估架构和业务设计：</strong> 结合实际情况重构、优化代码，使得消费者的处理速度与业务需求相匹配</p></li><li><p><strong>优化消费者代码</strong>：采用异步处理、批量处理、优化 SQL。</p></li><li><p><strong>增加消费者数量</strong>：利用 RabbitMQ 的 Work Queues 模式，横向扩展消费者实例。</p></li><li><p><strong>设置预取数量 (Prefetch Count)</strong>：不要让消费者一次拉取太多消息导致内存溢出，设置合理的 basicQos，让消费者“按需干活”。</p></li><li><p><strong>死信队列 (DLQ)</strong>：给队列设置 TTL（过期时间），过期的消息进入死信队列，避免堵塞主队列，事后人工处理死信，也可以自动+人工处理相结合。</p></li></ul><hr><h3 id="总结表格" tabindex="-1">总结表格 <a class="header-anchor" href="#总结表格" aria-label="Permalink to “总结表格”">​</a></h3><table tabindex="0"><thead><tr><th>问题</th><th>核心发生点</th><th>核心解决方案</th><th>关键词</th></tr></thead><tbody><tr><td><strong>消息丢失</strong></td><td>发送端、Broker、消费端</td><td>确认机制 + 持久化 + 手动 ACK</td><td>Publisher Confirm, Durable, Manual Ack</td></tr><tr><td><strong>消息重复</strong></td><td>网络波动、ACK 丢失</td><td>消费者端做<strong>幂等性</strong>处理</td><td>唯一 ID, Redis SETNX, 数据库唯一索引</td></tr><tr><td><strong>消息积压</strong></td><td>生产快、消费慢</td><td>临时扩容队列 + 分发逻辑</td><td>临时队列, 横向扩展, 异步优化</td></tr></tbody></table>',34)])])}const u=t(i,[["render",n]]);export{c as __pageData,u as default};
