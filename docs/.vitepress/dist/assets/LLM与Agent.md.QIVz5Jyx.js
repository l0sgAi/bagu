import{_ as n,c as r,o as a,ah as o}from"./chunks/framework.BqUCKHOO.js";const d=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"LLM与Agent.md","filePath":"LLM与Agent.md"}'),e={name:"LLM与Agent.md"};function l(i,t,g,s,h,p){return a(),r("div",null,[...t[0]||(t[0]=[o('<h3 id="一、-核心概念-agent-是什么" tabindex="-1">一、 核心概念（Agent 是什么？） <a class="header-anchor" href="#一、-核心概念-agent-是什么" aria-label="Permalink to “一、 核心概念（Agent 是什么？）”">​</a></h3><h4 id="_1-什么是-ai-agent-它和传统-chatbot-有什么区别" tabindex="-1">1. 什么是 AI Agent？它和传统 Chatbot 有什么区别？ <a class="header-anchor" href="#_1-什么是-ai-agent-它和传统-chatbot-有什么区别" aria-label="Permalink to “1. 什么是 AI Agent？它和传统 Chatbot 有什么区别？”">​</a></h4><p><strong>简答：</strong></p><ul><li><p><strong>定义：</strong> Agent 是一个以 LLM 为核心大脑，具备<strong>感知、规划、记忆、使用工具</strong>能力的自动化系统。</p></li><li><p><strong>区别：</strong></p><ul><li><p><strong>Chatbot (被动)：</strong> 主要是对话，给出建议，不产生实际副作用。</p></li><li><p><strong>Agent (主动)：</strong> 能够拆解目标，主动调用外部 API（如搜索、发邮件、查数据库）来完成复杂任务。</p></li></ul></li></ul><h4 id="_2-请解释-agent-的核心架构-coplanner-cognitive-architecture" tabindex="-1">2. 请解释 Agent 的核心架构（CoPlanner/Cognitive Architecture）？ <a class="header-anchor" href="#_2-请解释-agent-的核心架构-coplanner-cognitive-architecture" aria-label="Permalink to “2. 请解释 Agent 的核心架构（CoPlanner/Cognitive Architecture）？”">​</a></h4><p><strong>简答：</strong><br> 通常引用 Lilian Weng 的博文架构，包含四个要素：</p><ol><li><p><strong>Brain (LLM)：</strong> 负责推理、规划和指令生成。</p></li><li><p><strong>Planning (规划)：</strong> 将大目标拆解为子步骤（如 CoT, ReAct）。</p></li><li><p><strong>Memory (记忆)：</strong> 短期记忆（上下文）+ 长期记忆（向量数据库）。</p></li><li><p><strong>Tools (工具使用)：</strong> 调用外部 API 或计算器、解释器等执行动作。</p></li></ol><h4 id="_3-什么是-react-模式-为什么它很重要" tabindex="-1">3. 什么是 ReAct 模式？为什么它很重要？ <a class="header-anchor" href="#_3-什么是-react-模式-为什么它很重要" aria-label="Permalink to “3. 什么是 ReAct 模式？为什么它很重要？”">​</a></h4><p><strong>简答：</strong><br> ReAct = <strong>Reasoning（推理）+ Acting（行动）</strong>。<br> 它是 Agent 最基础的运行模式。模型在执行任务时，先思考“我该做什么”，生成行动（调用工具），然后观察工具返回的结果（Observation），再根据结果进行下一步推理。这让模型能通过“试错”和“反馈”解决复杂问题。</p><hr><h3 id="二、-关键组件与实现-怎么做" tabindex="-1">二、 关键组件与实现（怎么做？） <a class="header-anchor" href="#二、-关键组件与实现-怎么做" aria-label="Permalink to “二、 关键组件与实现（怎么做？）”">​</a></h3><h4 id="_4-llm-是如何调用外部工具-function-calling-的" tabindex="-1">4. LLM 是如何调用外部工具（Function Calling）的？ <a class="header-anchor" href="#_4-llm-是如何调用外部工具-function-calling-的" aria-label="Permalink to “4. LLM 是如何调用外部工具（Function Calling）的？”">​</a></h4><p><strong>简答：</strong><br> LLM 本身不能直接运行代码或发请求。</p><ol><li><p><strong>定义：</strong> 开发者在 Prompt 中描述工具的名称、功能和参数格式（通常是 JSON Schema）。</p></li><li><p><strong>生成：</strong> LLM 决定调用工具时，会输出一个结构化的 JSON（包含函数名和参数）。</p></li><li><p><strong>执行：</strong> 应用程序捕获这个 JSON，在本地运行对应的函数。</p></li><li><p><strong>反馈：</strong> 将函数运行结果拼接到 Prompt 中，再次发给 LLM 继续对话。</p></li></ol><h4 id="_5-什么是-chain-of-thought-cot-和-tree-of-thoughts-tot" tabindex="-1">5. 什么是 Chain of Thought (CoT) 和 Tree of Thoughts (ToT)？ <a class="header-anchor" href="#_5-什么是-chain-of-thought-cot-和-tree-of-thoughts-tot" aria-label="Permalink to “5. 什么是 Chain of Thought (CoT) 和 Tree of Thoughts (ToT)？”">​</a></h4><p><strong>简答：</strong></p><ul><li><p><strong>CoT (思维链)：</strong> 在 Prompt 中引导模型 &quot;Let&#39;s think step by step&quot;，让模型展示推理过程，能显著提高处理复杂逻辑的准确率。</p></li><li><p><strong>ToT (思维树)：</strong> CoT 的进阶版。让模型生成多个可能的推理路径（分支），并对每个路径进行自我评估，选择最优路径继续，类似于搜索算法（BFS/DFS）。</p></li></ul><h4 id="_6-agent-的记忆机制-memory-是如何设计的" tabindex="-1">6. Agent 的记忆机制（Memory）是如何设计的？ <a class="header-anchor" href="#_6-agent-的记忆机制-memory-是如何设计的" aria-label="Permalink to “6. Agent 的记忆机制（Memory）是如何设计的？”">​</a></h4><p><strong>简答：</strong></p><ul><li><p><strong>短期记忆：</strong> 直接利用 LLM 的 Context Window（上下文窗口），存储当前的对话历史。</p></li><li><p><strong>长期记忆：</strong> 使用 <strong>向量数据库 (Vector DB)</strong>。将历史交互转化为 Embedding 存入库中，需要时通过语义相似度检索相关历史，注入到 Prompt 中。</p></li><li><p><strong>总结记忆：</strong> 定期将长对话压缩总结（Summary），防止撑爆上下文。</p></li></ul><h4 id="_7-常见的-agent-开发框架有哪些-有什么区别" tabindex="-1">7. 常见的 Agent 开发框架有哪些？有什么区别？ <a class="header-anchor" href="#_7-常见的-agent-开发框架有哪些-有什么区别" aria-label="Permalink to “7. 常见的 Agent 开发框架有哪些？有什么区别？”">​</a></h4><p><strong>简答：</strong></p><ul><li><p><strong>LangChain:</strong> 最老牌，组件丰富，胶水层，适合构建 RAG 和基础 Chain。</p></li><li><p><strong>LlamaIndex:</strong> 专注于数据层，擅长处理 RAG、索引和数据检索。</p></li><li><p><strong>AutoGen / CrewAI:</strong> 专注于 <strong>Multi-Agent（多智能体）</strong> 协作，让多个角色（如程序员、测试员、产品经理）互相对话来完成任务。</p></li></ul><hr><h3 id="三、-rag-与数据增强-怎么懂知识" tabindex="-1">三、 RAG 与数据增强（怎么懂知识？） <a class="header-anchor" href="#三、-rag-与数据增强-怎么懂知识" aria-label="Permalink to “三、 RAG 与数据增强（怎么懂知识？）”">​</a></h3><h4 id="_8-什么是-rag-为什么-agent-需要-rag" tabindex="-1">8. 什么是 RAG？为什么 Agent 需要 RAG？ <a class="header-anchor" href="#_8-什么是-rag-为什么-agent-需要-rag" aria-label="Permalink to “8. 什么是 RAG？为什么 Agent 需要 RAG？”">​</a></h4><p><strong>简答：</strong><br> RAG（Retrieval-Augmented Generation，检索增强生成）。</p><ul><li><p><strong>原理：</strong> 先从知识库中检索相关信息，拼接到 Prompt 中，再让 LLM 回答。</p></li><li><p><strong>作用：</strong> 解决 LLM 的 <strong>幻觉问题（Hallucination）</strong> 和 <strong>时效性问题</strong>（训练数据截止），让 Agent 能基于私有数据回答。</p></li></ul><h4 id="_9-向量检索-vector-search-虽然好-但有什么局限性-怎么优化" tabindex="-1">9. 向量检索（Vector Search）虽然好，但有什么局限性？怎么优化？ <a class="header-anchor" href="#_9-向量检索-vector-search-虽然好-但有什么局限性-怎么优化" aria-label="Permalink to “9. 向量检索（Vector Search）虽然好，但有什么局限性？怎么优化？”">​</a></h4><p><strong>简答：</strong></p><ul><li><p><strong>局限：</strong> 基于语义相似度，有时会丢失关键词匹配（如搜专有名词、特定ID），且对“全文概括”类问题效果差。</p></li><li><p><strong>优化（Advanced RAG）：</strong></p><ol><li><p><strong>混合检索（Hybrid Search）：</strong> 向量检索 + 关键词检索（BM25），加权重排序（Re-rank）。</p></li><li><p><strong>父子索引（Parent-Child Indexing）：</strong> 检索小切片，送入大块上下文。</p></li><li><p><strong>GraphRAG：</strong> 引入知识图谱，增强实体间的关联推理。</p></li></ol></li></ul><hr><h3 id="四、-工程挑战与优化-怎么避坑" tabindex="-1">四、 工程挑战与优化（怎么避坑？） <a class="header-anchor" href="#四、-工程挑战与优化-怎么避坑" aria-label="Permalink to “四、 工程挑战与优化（怎么避坑？）”">​</a></h3><h4 id="_10-如何解决-llm-的-幻觉-问题" tabindex="-1">10. 如何解决 LLM 的“幻觉”问题？ <a class="header-anchor" href="#_10-如何解决-llm-的-幻觉-问题" aria-label="Permalink to “10. 如何解决 LLM 的“幻觉”问题？”">​</a></h4><p><strong>简答：</strong></p><ol><li><p><strong>Grounding（接地）：</strong> 强制要求模型仅依据 RAG 检索到的上下文回答，并引用来源。</p></li><li><p><strong>Self-Correction（自查）：</strong> 让模型生成后，再加一步“请检查上述回答是否符合事实”，进行自我反思。</p></li><li><p><strong>降低温度（Temperature）：</strong> 设为 0，减少随机性。</p></li></ol><h4 id="_11-multi-agent-多智能体-架构解决了什么问题" tabindex="-1">11. Multi-Agent（多智能体）架构解决了什么问题？ <a class="header-anchor" href="#_11-multi-agent-多智能体-架构解决了什么问题" aria-label="Permalink to “11. Multi-Agent（多智能体）架构解决了什么问题？”">​</a></h4><p><strong>简答：</strong><br> 解决了单体 Agent <strong>注意力分散</strong> 和 <strong>上下文过长</strong> 的问题。<br> 通过让不同的 Agent 扮演不同角色（Role-Playing），各司其职（例如一个负责写代码，一个负责运行代码并报错），可以处理更复杂的任务流程，且每个 Agent 只需维护自己的 Prompt 上下文。</p><h4 id="_12-agent-开发中如何评估-evaluation-效果" tabindex="-1">12. Agent 开发中如何评估（Evaluation）效果？ <a class="header-anchor" href="#_12-agent-开发中如何评估-evaluation-效果" aria-label="Permalink to “12. Agent 开发中如何评估（Evaluation）效果？”">​</a></h4><p><strong>简答：</strong><br> 这是一个难点。常用方法：</p><ol><li><p><strong>LLM-as-a-Judge：</strong> 用更强的模型（如 GPT-4）给弱模型的输出打分。</p></li><li><p><strong>Ragas 框架：</strong> 评估 RAG 的检索准确性（Context Precision）和生成忠实度（Faithfulness）。</p></li><li><p><strong>端到端测试：</strong> 设定固定任务集，检查工具调用是否成功，结果是否符合预期。</p></li></ol><hr>',42)])])}const A=n(e,[["render",l]]);export{d as __pageData,A as default};
